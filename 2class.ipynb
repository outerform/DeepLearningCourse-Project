{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "from scipy import optimize\n",
    "\n",
    "\n",
    "class args:\n",
    "    batch_size = 12\n",
    "    n_worker = 8\n",
    "\n",
    "    image_size = 512\n",
    "    arch_name = 'tf_efficientnetv2_l.in21k'\n",
    "    epochs = 20\n",
    "    lr = 1e-4\n",
    "    drop_rate = 0.45\n",
    "    drop_path_rate = 0.1\n",
    "\n",
    "    loss_fn = \"FocalLoss\"\n",
    "    focal_alpha = 0.6\n",
    "    focal_gamma = 1.8\n",
    "    aux_loss = 'binary_cross_entropy'\n",
    "\n",
    "\n",
    "    loss1_coef = 1\n",
    "    optimizer = 'AdamW'\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    scheduler_warmup = None # \"GradualWarmupSchedulerV3\"\n",
    "    warmup_factor = 2\n",
    "    warmup_epo = 5\n",
    "    T_max = epochs - 1\n",
    "    weight_decay = 2e-3\n",
    "\n",
    "    save_path = './models_2class/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_label_image = pd.read_csv('./siim-covid19-detection/train_image_level.csv')\n",
    "train_label_study = pd.read_csv('./siim-covid19-detection/train_study_level.csv')\n",
    "\n",
    "# train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_id = set()\n",
    "# boxes_study_id= set()\n",
    "# uniqued_train_label_image = pd.DataFrame(columns = train_label_image.columns)\n",
    "\n",
    "# for idx,image_id,boxes,label,StudyInstanceUID in train_label_image.itertuples():\n",
    "#     # break\n",
    "#     if StudyInstanceUID not in study_id:\n",
    "#         study_id.add(StudyInstanceUID)\n",
    "#         # check if opacity in label\n",
    "#         if label.find('none') == -1:\n",
    "#             boxes_study_id.add(StudyInstanceUID)\n",
    "#         # print(uniqued_train_label_image.columns)\n",
    "#         # print(train_label_image.iloc[idx])\n",
    "#         uniqued_train_label_image = uniqued_train_label_image.append(train_label_image.iloc[idx])\n",
    "#         # print(uniqued_train_label_image.columns)\n",
    "#         # break\n",
    "#     else:\n",
    "#         if StudyInstanceUID in boxes_study_id:\n",
    "#             continue\n",
    "#         elif label.find('none') == -1:\n",
    "#             boxes_study_id.add(StudyInstanceUID)\n",
    "#             uniqued_train_label_image.loc[uniqued_train_label_image['StudyInstanceUID'] == StudyInstanceUID] = [image_id,boxes,label,StudyInstanceUID]\n",
    "\n",
    "# uniqued_train_label_image = uniqued_train_label_image.reset_index(drop=True)\n",
    "uniqued_train_label_image = train_label_image\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_study['StudyInstanceUID'] = train_label_study['id'].apply(lambda x: x.replace('_study',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(uniqued_train_label_image,train_label_study,on='StudyInstanceUID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'id_x':'id_image'},inplace=True)\n",
    "train_df.drop(['id_y'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id_image'] = train_df['id_image'].apply(lambda x: x.replace('_image',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_image</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>ffcc6edd9445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>7e6c68462e06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>ffd91a2c4ca0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>8332bdaddb6e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>ffd9b6cf2961</td>\n",
       "      <td>[{'x': 2197.38566, 'y': 841.07361, 'width': 31...</td>\n",
       "      <td>opacity 1 2197.38566 841.07361 2513.80265 1292...</td>\n",
       "      <td>7eed9af03814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>ffdc682f7680</td>\n",
       "      <td>[{'x': 2729.27083, 'y': 332.26044, 'width': 14...</td>\n",
       "      <td>opacity 1 2729.27083 332.26044 4225.52099 2936...</td>\n",
       "      <td>a0cb0b96fb3d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>ffe942c8655f</td>\n",
       "      <td>[{'x': 208.86463, 'y': 91.53448, 'width': 450....</td>\n",
       "      <td>opacity 1 208.86463 91.53448 659.8321 719.5892...</td>\n",
       "      <td>7d82d53204b8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_image                                              boxes  \\\n",
       "0     000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1     000c3a3f293f                                                NaN   \n",
       "2     0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3     001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4     001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "...            ...                                                ...   \n",
       "6329  ffcc6edd9445                                                NaN   \n",
       "6330  ffd91a2c4ca0                                                NaN   \n",
       "6331  ffd9b6cf2961  [{'x': 2197.38566, 'y': 841.07361, 'width': 31...   \n",
       "6332  ffdc682f7680  [{'x': 2729.27083, 'y': 332.26044, 'width': 14...   \n",
       "6333  ffe942c8655f  [{'x': 208.86463, 'y': 91.53448, 'width': 450....   \n",
       "\n",
       "                                                  label StudyInstanceUID  \\\n",
       "0     opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                        none 1 0 0 1 1     ff0879eb20ed   \n",
       "2     opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3       opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4     opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "...                                                 ...              ...   \n",
       "6329                                     none 1 0 0 1 1     7e6c68462e06   \n",
       "6330                                     none 1 0 0 1 1     8332bdaddb6e   \n",
       "6331  opacity 1 2197.38566 841.07361 2513.80265 1292...     7eed9af03814   \n",
       "6332  opacity 1 2729.27083 332.26044 4225.52099 2936...     a0cb0b96fb3d   \n",
       "6333  opacity 1 208.86463 91.53448 659.8321 719.5892...     7d82d53204b8   \n",
       "\n",
       "      Negative for Pneumonia  Typical Appearance  Indeterminate Appearance  \\\n",
       "0                          0                   1                         0   \n",
       "1                          1                   0                         0   \n",
       "2                          0                   1                         0   \n",
       "3                          0                   0                         0   \n",
       "4                          0                   1                         0   \n",
       "...                      ...                 ...                       ...   \n",
       "6329                       1                   0                         0   \n",
       "6330                       1                   0                         0   \n",
       "6331                       0                   1                         0   \n",
       "6332                       0                   1                         0   \n",
       "6333                       0                   1                         0   \n",
       "\n",
       "      Atypical Appearance  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       0  \n",
       "...                   ...  \n",
       "6329                    0  \n",
       "6330                    0  \n",
       "6331                    0  \n",
       "6332                    0  \n",
       "6333                    0  \n",
       "\n",
       "[6334 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['filepath'] = './tmp/train/'+train_df['id_image']+'.png'\n",
    "train_df['label_2class'] = train_df['label'].apply(lambda x: 1 if x.find('opacity') != -1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "folds = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for fold\n",
    "train_df['fold_id'] = -1\n",
    "for fold_id,(train_idx,valid_idx) in enumerate(folds.split(train_df,groups=train_df.StudyInstanceUID.tolist())):\n",
    "    train_df.loc[valid_idx,'fold_id'] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_image</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>filepath</th>\n",
       "      <th>label_2class</th>\n",
       "      <th>fold_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/000a312787f2.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/000c3a3f293f.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/0012ff7358bc.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>./tmp/train/001398f4ff4f.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/001bd15d1891.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>ffcc6edd9445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>7e6c68462e06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/ffcc6edd9445.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>ffd91a2c4ca0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>8332bdaddb6e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/ffd91a2c4ca0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>ffd9b6cf2961</td>\n",
       "      <td>[{'x': 2197.38566, 'y': 841.07361, 'width': 31...</td>\n",
       "      <td>opacity 1 2197.38566 841.07361 2513.80265 1292...</td>\n",
       "      <td>7eed9af03814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/ffd9b6cf2961.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>ffdc682f7680</td>\n",
       "      <td>[{'x': 2729.27083, 'y': 332.26044, 'width': 14...</td>\n",
       "      <td>opacity 1 2729.27083 332.26044 4225.52099 2936...</td>\n",
       "      <td>a0cb0b96fb3d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/ffdc682f7680.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>ffe942c8655f</td>\n",
       "      <td>[{'x': 208.86463, 'y': 91.53448, 'width': 450....</td>\n",
       "      <td>opacity 1 208.86463 91.53448 659.8321 719.5892...</td>\n",
       "      <td>7d82d53204b8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./tmp/train/ffe942c8655f.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_image                                              boxes  \\\n",
       "0     000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1     000c3a3f293f                                                NaN   \n",
       "2     0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3     001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4     001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "...            ...                                                ...   \n",
       "6329  ffcc6edd9445                                                NaN   \n",
       "6330  ffd91a2c4ca0                                                NaN   \n",
       "6331  ffd9b6cf2961  [{'x': 2197.38566, 'y': 841.07361, 'width': 31...   \n",
       "6332  ffdc682f7680  [{'x': 2729.27083, 'y': 332.26044, 'width': 14...   \n",
       "6333  ffe942c8655f  [{'x': 208.86463, 'y': 91.53448, 'width': 450....   \n",
       "\n",
       "                                                  label StudyInstanceUID  \\\n",
       "0     opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                        none 1 0 0 1 1     ff0879eb20ed   \n",
       "2     opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3       opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4     opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "...                                                 ...              ...   \n",
       "6329                                     none 1 0 0 1 1     7e6c68462e06   \n",
       "6330                                     none 1 0 0 1 1     8332bdaddb6e   \n",
       "6331  opacity 1 2197.38566 841.07361 2513.80265 1292...     7eed9af03814   \n",
       "6332  opacity 1 2729.27083 332.26044 4225.52099 2936...     a0cb0b96fb3d   \n",
       "6333  opacity 1 208.86463 91.53448 659.8321 719.5892...     7d82d53204b8   \n",
       "\n",
       "      Negative for Pneumonia  Typical Appearance  Indeterminate Appearance  \\\n",
       "0                          0                   1                         0   \n",
       "1                          1                   0                         0   \n",
       "2                          0                   1                         0   \n",
       "3                          0                   0                         0   \n",
       "4                          0                   1                         0   \n",
       "...                      ...                 ...                       ...   \n",
       "6329                       1                   0                         0   \n",
       "6330                       1                   0                         0   \n",
       "6331                       0                   1                         0   \n",
       "6332                       0                   1                         0   \n",
       "6333                       0                   1                         0   \n",
       "\n",
       "      Atypical Appearance                      filepath  label_2class  fold_id  \n",
       "0                       0  ./tmp/train/000a312787f2.png             1        4  \n",
       "1                       0  ./tmp/train/000c3a3f293f.png             0        0  \n",
       "2                       0  ./tmp/train/0012ff7358bc.png             1        4  \n",
       "3                       1  ./tmp/train/001398f4ff4f.png             1        1  \n",
       "4                       0  ./tmp/train/001bd15d1891.png             1        3  \n",
       "...                   ...                           ...           ...      ...  \n",
       "6329                    0  ./tmp/train/ffcc6edd9445.png             0        3  \n",
       "6330                    0  ./tmp/train/ffd91a2c4ca0.png             0        3  \n",
       "6331                    0  ./tmp/train/ffd9b6cf2961.png             1        2  \n",
       "6332                    0  ./tmp/train/ffdc682f7680.png             1        1  \n",
       "6333                    0  ./tmp/train/ffe942c8655f.png             1        3  \n",
       "\n",
       "[6334 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_limit = 20\n",
    "scale_limit = 0.7\n",
    "shift_limit =  0.3\n",
    "num_holes = 8\n",
    "max_h_size = 0.05\n",
    "max_w_size = 0.05"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/outerform/anaconda3/envs/ml/lib/python3.7/site-packages/albumentations/augmentations/dropout/cutout.py:51: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import RandomCrop,HorizontalFlip,VerticalFlip,Rotate,RandomBrightnessContrast,\\\n",
    "    RandomResizedCrop,Normalize,Resize,Compose,GaussianBlur,RandomBrightness,RandomContrast,RandomGamma,RandomRotate90,Transpose,\\\n",
    "    ShiftScaleRotate,Blur,OpticalDistortion,GridDistortion,HueSaturationValue,IAAAdditiveGaussianNoise,IAAPerspective,RandomSizedCrop,\\\n",
    "    RandomShadow,RandomSnow,RandomRain,RandomFog,CenterCrop,CoarseDropout,ChannelShuffle,ToGray,Cutout,PadIfNeeded,RandomCrop,VerticalFlip,HorizontalFlip,\\\n",
    "    Transpose,RandomRotate90,ShiftScaleRotate,ElasticTransform,GridDistortion,OpticalDistortion,RandomSizedCrop,HueSaturationValue,RGBShift,RandomBrightnessContrast,\\\n",
    "    RandomGamma,CLAHE,Blur,MedianBlur,MotionBlur,GaussNoise,GaussianBlur,RGBShift,RandomBrightnessContrast,IAAEmboss,IAASharpen,IAASuperpixels,RandomFog,RandomRain,\\\n",
    "    RandomShadow,RandomSnow,RandomSunFlare\n",
    "transform_train = albumentations.Compose([\n",
    "    RandomCrop(args.image_size,args.image_size),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    ShiftScaleRotate(p=0.7,shift_limit=shift_limit,scale_limit=scale_limit,rotate_limit=rotate_limit),\n",
    "    Cutout(p=0.7,num_holes=8,max_h_size=int(args.image_size*max_h_size),max_w_size=int(args.image_size*max_w_size))\n",
    "    ],\n",
    "    additional_targets={'mask':'image'})\n",
    "transform_train_image = albumentations.Compose([\n",
    "    RandomBrightnessContrast(p=0.1,brightness_limit=0.3,contrast_limit=0.3),\n",
    "    HueSaturationValue(p=0.1,hue_shift_limit=20,sat_shift_limit=50,val_shift_limit=40),\n",
    "    Normalize()])\n",
    "transform_valid = albumentations.Compose([\n",
    "    Resize(args.image_size,args.image_size),\n",
    "    Normalize()],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor,Normalize,Compose,Resize\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df,transform=None,mode:str='train'):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row.filepath).convert('RGB')\n",
    "        if self.mode == 'train':\n",
    "            mask_img = Image.open(row.filepath.replace('train','train_mask')).convert('RGB')\n",
    "            transformed = self.transform[0](image=np.array(img),mask=np.array(mask_img))\n",
    "            mask_img = transformed['mask'].transpose(2,0,1)/255\n",
    "            img = self.transform[1](image=transformed['image'])['image'].transpose(2,0,1)\n",
    "            # print(row)\n",
    "            label = torch.zeros(2).float()\n",
    "            label = label.scatter_(0,torch.tensor(row['label_2class']).long(),1)\n",
    "            return img,mask_img,label\n",
    "        elif self.mode == 'valid':\n",
    "            img = self.transform(image=np.array(img))['image'].transpose(2,0,1)\n",
    "            label = torch.zeros(2).float()\n",
    "            label = label.scatter_(0,torch.tensor(row['label_2class']).long(),1)\n",
    "            return img,label\n",
    "        elif self.mode == 'test':\n",
    "            img = self.transform(image=np.array(img))['image'].transpose(2,0,1)\n",
    "            return img\n",
    "        else:\n",
    "            raise ValueError('mode must be train or valid or test')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_df,transform=[transform_train,transform_train_image],mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in train_df[[\"Negative for Pneumonia\",\"label_2class\"]].itertuples():\n",
    "#     if row[1]+row[2]!=1:\n",
    "#         print(row[0])\n",
    "#         print(train_df.iloc[22])\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_image                                    00c1515729a8\n",
       "boxes                                                NaN\n",
       "label                                     none 1 0 0 1 1\n",
       "StudyInstanceUID                            1a58b43cf286\n",
       "Negative for Pneumonia                                 0\n",
       "Typical Appearance                                     1\n",
       "Indeterminate Appearance                               0\n",
       "Atypical Appearance                                    0\n",
       "filepath                    ./tmp/train/00c1515729a8.png\n",
       "label_2class                                           0\n",
       "fold_id                                                1\n",
       "Name: 22, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[22]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import adaptive_max_pool1d\n",
    "from torch.utils.data import DataLoader\n",
    "#effnetv2\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.nn import AvgPool2d,AdaptiveAvgPool2d\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=True, reduce = 'mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "    \n",
    "    def forward(self,inputs,targets):\n",
    "        if self.logits:\n",
    "            loss = nn.BCEWithLogitsLoss()(inputs,targets)\n",
    "        else:\n",
    "            loss = nn.CrossEntropyLoss()(inputs,targets)\n",
    "        pt = torch.exp(-loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * loss\n",
    "        if self.reduce is not None:\n",
    "            return torch.__getattribute__(self.reduce)(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "class Swish(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return x * torch.sigmoid(x)\n",
    "        \n",
    "class Effnetv2(nn.Module):\n",
    "    def __init__(self,pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(args.arch_name,pretrained=pretrained,num_classes=2,drop_rate = args.drop_rate,drop_path_rate=args.drop_path_rate)\n",
    "        self.logit = nn.Linear(self.model.classifier.in_features,2)\n",
    "        self.preprocess = nn.Sequential(\n",
    "            self.model.conv_stem,\n",
    "            self.model.bn1,\n",
    "            Swish()\n",
    "        )\n",
    "        self.blocks = self.model.blocks\n",
    "        self.mask = nn.Sequential(\n",
    "            nn.Conv2d(224, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "             self.model.conv_head,\n",
    "                self.model.bn2,\n",
    "                Swish(),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        batch_size = len(x)\n",
    "        x = self.preprocess(x)\n",
    "        for block in self.blocks[:5]:\n",
    "            x = block(x)\n",
    "        mask = self.mask(x)\n",
    "        for block in self.blocks[5:]:\n",
    "            x = block(x)\n",
    "        x = self.classifier(x)\n",
    "        x = AdaptiveAvgPool2d((1,1))(x)\n",
    "        return self.logit(x.view(batch_size,-1)),mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2dxr915d) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e573b2b420cb4d669bf04e1211bc0f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">effnetv2-2class</strong>: <a href=\"https://wandb.ai/outerform/siim-covid19-detection/runs/2dxr915d\" target=\"_blank\">https://wandb.ai/outerform/siim-covid19-detection/runs/2dxr915d</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230627_024704-2dxr915d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2dxr915d). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/outerform/github-repo/DeepLearningCourse-Project/wandb/run-20230627_025034-2hp697wv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/outerform/siim-covid19-detection/runs/2hp697wv\" target=\"_blank\">effnetv2-2class</a></strong> to <a href=\"https://wandb.ai/outerform/siim-covid19-detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/outerform/siim-covid19-detection/runs/2hp697wv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f05004de750>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project='siim-covid19-detection',name='effnetv2-2class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import auto\n",
    "from numpy import average\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import GradScaler,autocast\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "scaler = GradScaler()\n",
    "class Trainer:\n",
    "    def __init__(self,model,train_dataloader, valid_dataloader) -> None:\n",
    "        self.model = model\n",
    "\n",
    "    def accuracy(outputs,targets,logits = True):\n",
    "        outputs = torch.argmax(outputs,dim=1)\n",
    "        if logits:\n",
    "            targets = torch.argmax(targets,dim=1)\n",
    "        return (outputs == targets).float().mean()\n",
    "    \n",
    "    def train(self,train_dataloader,optimizer, loss_fn = \"BCEWithLogitsLoss\",aux_loss = \"binary_cross_entropy\",_scheduler = 'CosineAnnealingLR',T_max = 10,eta_min = 1e-6,valid_dataloader = None,device = 'cuda:0',aux_weight = 0.1,epochs = 10,verbose = True,save_path = None,save = True,save_best = True,early_stopping = True,patience = 5,):\n",
    "        \n",
    "        if loss_fn == 'BCEWithLogitsLoss':\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif loss_fn == 'CrossEntropyLoss':\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        elif loss_fn == 'FocalLoss':\n",
    "            criterion = FocalLoss()\n",
    "        else:\n",
    "            raise ValueError('loss_fn must be BCEWithLogitsLoss or CrossEntropyLoss or FocalLoss')\n",
    "        \n",
    "        if aux_loss == 'binary_cross_entropy':\n",
    "            aux_criterion = F.binary_cross_entropy_with_logits\n",
    "        else:\n",
    "            raise ValueError('aux_loss must be binary_cross_entropy')\n",
    "        model=self.model\n",
    "        model.train()\n",
    "        losses = []\n",
    "        aux_losses = []\n",
    "        loss0s = []\n",
    "        accs = []\n",
    "        with tqdm(enumerate(train_dataloader),total=len(train_dataloader)) as pbar:\n",
    "            for idx,(img,mask_img,label) in pbar:\n",
    "                img = img.to(device)\n",
    "                # print(img)\n",
    "                mask_img = mask_img.to(device)\n",
    "                mask_img = mask_img[:,0:1,:,:]\n",
    "                # print(mask_img)\n",
    "                mask_img = F.interpolate(mask_img,(32,32), mode='bilinear', align_corners=False)\n",
    "                \n",
    "                label = label.to(device)\n",
    "                with autocast():\n",
    "                    optimizer.zero_grad()\n",
    "                    logits,mask = model(img)\n",
    "                    if loss_fn == 'CrossEntropyLoss':\n",
    "                        loss0 = criterion(logits,label.argmax(-1))\n",
    "                    else:\n",
    "                        loss0 = criterion(logits,label)\n",
    "                    aux_loss = aux_criterion(mask,mask_img)*aux_weight\n",
    "                    scaler.scale(loss0+aux_loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    accs.append(Trainer.accuracy(logits,label).item())\n",
    "                    aux_losses.append(aux_loss.item())\n",
    "                    loss0s.append(loss0.item())\n",
    "                    losses.append((loss0+aux_loss).item())\n",
    "                    pbar.set_postfix(loss=losses[-1])\n",
    "                    if (idx+1) % 100 == 0:\n",
    "                        # pbar.write(f'idx:{idx+1},loss:{np.mean(losses)},acc:{np.mean(accs)}')\n",
    "                        wandb.log({\"train_loss\": np.mean(losses),\"train_acc\":np.mean(accs)})\n",
    "        return losses,accs,optimizer\n",
    "\n",
    "    def valid(self,valid_dataloader,loss_fn = \"BCEWithLogitsLoss\",device = 'cuda:0'):\n",
    "        model = self.model\n",
    "        model.eval()\n",
    "        losses = []\n",
    "        accs = []\n",
    "        preds = []\n",
    "        targets = []\n",
    "        if loss_fn == 'BCEWithLogitsLoss':\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif loss_fn == 'CrossEntropyLoss':\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        elif loss_fn == 'FocalLoss':\n",
    "            criterion = FocalLoss()\n",
    "        else:\n",
    "            raise ValueError('loss_fn must be BCEWithLogitsLoss or CrossEntropyLoss or FocalLoss')\n",
    "        with torch.no_grad():\n",
    "            with tqdm(enumerate(valid_dataloader),total=len(valid_dataloader)) as pbar:\n",
    "                for idx,(img,label) in pbar:\n",
    "                    img = img.to(device)\n",
    "                    label = label.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        logits,mask = model(img)\n",
    "                        if loss_fn == 'CrossEntropyLoss':\n",
    "                            loss = criterion(logits,label.argmax(-1))\n",
    "                        else:\n",
    "                            loss = criterion(logits,label)\n",
    "                        # accuracy = lambda x,y: (x.argmax(-1) == y.argmax(-1)).float().mean()\n",
    "                        accs.append(Trainer.accuracy(logits,label).item())\n",
    "                        losses.append(loss.item())\n",
    "                        preds.append(logits.cpu().numpy())\n",
    "                        targets.append(label.cpu().numpy())\n",
    "                        pbar.set_postfix(loss=loss.item(),acc=accs[-1])\n",
    "        preds = np.concatenate(preds,axis=0)\n",
    "        targets = np.concatenate(targets,axis=0)\n",
    "        ap = average_precision_score(targets,preds)\n",
    "        wandb.log({\"valid_loss\": np.mean(losses),\"valid_acc\":np.mean(accs),\"average_precision_score\":ap})\n",
    "        return losses,accs,np.concatenate(preds,axis=0),ap\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b10fb6f9d448418b4c34311f592744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511e1012f5504a72ad075bb7c00604f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,train_loss:0.4894992482224336,train_acc:0.7354216125417263,valid_loss:0.0726692177144424,valid_acc:0.7905435961372448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecfe0a589a2846f980e0e1f0774a8caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from math import e\n",
    "from torch.optim import AdamW,Adam,SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,ReduceLROnPlateau,CosineAnnealingWarmRestarts\n",
    "import shutil\n",
    "\n",
    "import transformers\n",
    "\n",
    "def get_dataloader(fold,df):\n",
    "    train_df = df[df.fold_id != fold]\n",
    "    valid_df = df[df.fold_id == fold]\n",
    "    train_dataset = MyDataset(train_df,transform = [transform_train,transform_train_image],mode = 'train')\n",
    "    valid_dataset = MyDataset(valid_df,transform = transform_valid,mode = 'valid')\n",
    "    train_dataloader = DataLoader(train_dataset,batch_size=args.batch_size,shuffle=True,num_workers=args.n_worker,pin_memory=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset,batch_size=args.batch_size,shuffle=False,num_workers=args.n_worker,pin_memory=True)\n",
    "\n",
    "    return train_dataloader,valid_dataloader\n",
    "model = Effnetv2()\n",
    "model.to(device)\n",
    "os.makedirs(args.save_path,exist_ok=True)\n",
    "for fold in range(5):\n",
    "    train_dataloader,valid_dataloader = get_dataloader(fold,train_df)\n",
    "    trainer = Trainer(model,train_dataloader,valid_dataloader)\n",
    "    if args.optimizer == 'AdamW':\n",
    "        optimizer = AdamW(model.parameters(),lr=args.lr\n",
    "                            ,weight_decay=args.weight_decay)\n",
    "    elif args.optimizer == 'Adam':\n",
    "        optimizer = Adam(model.parameters(),lr=args.lr\n",
    "                            ,weight_decay=args.weight_decay)\n",
    "    elif args.optimizer == 'SGD':\n",
    "        optimizer = SGD(model.parameters(),lr=args.lr)\n",
    "    else:\n",
    "        raise ValueError('optimizer must be AdamW or Adam or SGD')\n",
    "\n",
    "    # if args.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "    #     scheduler = CosineAnnealingWarmRestarts(optimizer)\n",
    "    if args.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(optimizer,T_max=args.T_max)\n",
    "    elif args.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer,mode='min',factor=args.factor,patience=args.patience,verbose=True)\n",
    "    else:\n",
    "        raise ValueError('scheduler must be CosineAnnealingWarmRestarts or CosineAnnealingLR or ReduceLROnPlateau')\n",
    "    best = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        train_losses,train_accs,optimizer = trainer.train(train_dataloader,valid_dataloader=valid_dataloader,device=device,loss_fn=args.loss_fn,aux_loss=args.aux_loss,optimizer=optimizer,aux_weight=args.loss1_coef)\n",
    "        valid_losses,valid_accs,valid_preds,ap = trainer.valid(valid_dataloader,device=device,loss_fn=args.loss_fn)\n",
    "        scheduler.step()\n",
    "        if ap > best:\n",
    "            best = ap\n",
    "            best_epoch = epoch\n",
    "        print(f'epoch:{epoch},train_loss:{np.mean(train_losses)},train_acc:{np.mean(train_accs)},valid_loss:{np.mean(valid_losses)},valid_acc:{np.mean(valid_accs)}')\n",
    "        torch.save(model.state_dict(),os.path.join(args.save_path,f'fold{fold}_epoch{epoch}.pth'))\n",
    "    shutil.copy(os.path.join(args.save_path,f'fold{fold}_epoch{best_epoch}.pth'),os.path.join(args.save_path,f'fold{fold}_best.pth'))\n",
    "    wandb.log({\"best_epoch\": best_epoch,\"best_ap\":best})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362c24f486b74c7192a9b854099f3a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_losses,valid_accs,valid_preds,ap = trainer.valid(valid_dataloader,device=device,loss_fn=args.loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetv2_rw_m.agc_in1k\n",
      "efficientnetv2_rw_s.ra2_in1k\n",
      "efficientnetv2_rw_t.ra2_in1k\n",
      "gc_efficientnetv2_rw_t.agc_in1k\n",
      "tf_efficientnetv2_b0.in1k\n",
      "tf_efficientnetv2_b1.in1k\n",
      "tf_efficientnetv2_b2.in1k\n",
      "tf_efficientnetv2_b3.in1k\n",
      "tf_efficientnetv2_b3.in21k\n",
      "tf_efficientnetv2_b3.in21k_ft_in1k\n",
      "tf_efficientnetv2_l.in1k\n",
      "tf_efficientnetv2_l.in21k\n",
      "tf_efficientnetv2_l.in21k_ft_in1k\n",
      "tf_efficientnetv2_m.in1k\n",
      "tf_efficientnetv2_m.in21k\n",
      "tf_efficientnetv2_m.in21k_ft_in1k\n",
      "tf_efficientnetv2_s.in1k\n",
      "tf_efficientnetv2_s.in21k\n",
      "tf_efficientnetv2_s.in21k_ft_in1k\n",
      "tf_efficientnetv2_xl.in21k\n",
      "tf_efficientnetv2_xl.in21k_ft_in1k\n"
     ]
    }
   ],
   "source": [
    "# for x in timm.list_models(pretrained=True):\n",
    "#     if x.find('efficientnetv2') != -1:\n",
    "#         print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3435"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.metrics import average_precision_score\n",
    "# x = np.array([[0.2,0.0],[0.3,0.7]])\n",
    "# y = np.array([[0,1],[1,0]])\n",
    "# average_precision_score(y,x)\n",
    "#get number of files\n",
    "# len(os.listdir('./data/train/labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
